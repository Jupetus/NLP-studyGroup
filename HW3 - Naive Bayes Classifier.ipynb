{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================\n",
    "# From pure python to notebook for easier read!\n",
    "#===============================\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes says a class $c$ is given as\n",
    "\n",
    "\\begin{equation}\n",
    "c = P(c) + \\sum log( P(w_i | c)\n",
    "\\end{equation}\n",
    "Where $P(c)$ is prior for the class and $P(w_i | c)$ is probability for the word, when we know the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos:  -17.384020030246134  Neg:  -16.683033733185496\n"
     ]
    }
   ],
   "source": [
    "# ================\n",
    "# Assignment 6.1\n",
    "# What  class  will  Naive  bayes  assign  to  the  sentence  “I  always  like  foreign films.”\n",
    "\n",
    "# Probabilities:\n",
    "# word     pos    neg\n",
    "# -------------------\n",
    "# I        0.09  0.16\n",
    "# always   0.07  0.06\n",
    "# like     0.29  0.06\n",
    "# foreign  0.04  0.15\n",
    "# films    0.08  0.11\n",
    "# ================\n",
    "\n",
    "p_pos  = np.log2(0.09) + np.log2(0.07) + np.log2(0.29) + np.log2(0.04) + np.log2(0.08)\n",
    "p_neg = np.log2(0.16) + np.log2(0.06) +  np.log2(0.06) + np.log2(0.15) + np.log2(0.11)\n",
    "\n",
    "# Result!\n",
    "print(\"Pos: \", p_pos , \" Neg: \", p_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  -8.671115273688494  Comedy:  -9.52173897104528\n"
     ]
    }
   ],
   "source": [
    "# ================\n",
    "# Assignment 6.2\n",
    "# Given the following short movie reviews,  each labeled with a genre,  either comedy or action:\n",
    "# What is the most likely class for document [fast, couple, shoot, fly]\n",
    "# ================\n",
    "\n",
    "# Set the priors!\n",
    "prior_comedy = 2 / 5\n",
    "prior_action = 3 / 5\n",
    "\n",
    "# Documents (notice multiple occurances)\n",
    "action_sentances = [\"fast\", \"furious\", \"shoot\", \"furious\", \"shoot\", \"shoot\", \"fun\", \"fly\", \"fast\", \"shoot\", \"love\"]\n",
    "comdey_sentances = [\"fun\", \"couple\", \"love\", \"love\", \"couple\", \"fly\", \"fast\", \"fun\", \"fun\"]\n",
    "document = [\"fast\", \"couple\", \"shoot\", \"fly\"]\n",
    "\n",
    "# Calculate how many times word occurs\n",
    "action_unigram = Counter(action_sentances)\n",
    "comedy_unigram = Counter(comdey_sentances)\n",
    "total_unigram = Counter(action_sentances + comdey_sentances)\n",
    "\n",
    "# Initialise probabilities with priors\n",
    "action_posterior = np.log(prior_action)\n",
    "comedy_posterior = np.log(prior_comedy)\n",
    "action_count = sum(action_unigram.values())\n",
    "comedy_count = sum(comedy_unigram.values())\n",
    "\n",
    "# Loop over the query document!\n",
    "for word in document:\n",
    "    action_posterior += np.log((action_unigram[word] + 1) / (action_count + len(total_unigram)))\n",
    "    comedy_posterior += np.log((comedy_unigram[word] + 1) / (comedy_count + len(total_unigram)))\n",
    "\n",
    "# Result!\n",
    "print(\"Action: \", action_posterior, \" Comedy: \", comedy_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  -8.076815597050832  Negative:  -8.872497838366797\n",
      "=================\n",
      "Positive (bin):  -7.966385282396622  Negative: (bin) -7.246740598493144\n"
     ]
    }
   ],
   "source": [
    "# ================\n",
    "# Assignment 6.3\n",
    "# Multinomial and binary bayes --- Do they agree!?\n",
    "# ================\n",
    "\n",
    "sentance = \"A good good plot and great characters but poor acting\".split()\n",
    "classes = [\"pos\", \"neg\"]\n",
    "documents = [\n",
    "    (\"pos\",[\"good\", \"good\", \"good\", \"great\", \"great\", \"great\"]),\n",
    "    (\"pos\",[\"poor\", \"great\", \"great\"]),\n",
    "    (\"neg\",[\"good\", \"poor\", \"poor\", \"poor\"]),\n",
    "    (\"neg\",[\"good\", \"poor\", \"poor\", \"poor\", \"poor\", \"poor\", \"great\", \"great\"]),\n",
    "    (\"neg\",[\"poor\", \"poor\"])\n",
    "]\n",
    "\n",
    "# Calculate counts in the documents\n",
    "counters = {}\n",
    "counters_bin = {}\n",
    "counters[\"pos\"] = Counter()\n",
    "counters[\"neg\"] = Counter()\n",
    "counters_bin[\"pos\"] = Counter()\n",
    "counters_bin[\"neg\"] = Counter()\n",
    "for C in classes:\n",
    "    for p, document in documents:\n",
    "        if C == p:\n",
    "            counters[C] += Counter(document)\n",
    "            counters_bin[C] += Counter(set(document))\n",
    "\n",
    "counters[\"tot\"] = counters[\"neg\"] + counters[\"pos\"]\n",
    "counters_bin[\"tot\"] = counters_bin[\"neg\"] + counters_bin[\"pos\"]\n",
    "\n",
    "# Start calculating the posteriors\n",
    "pos_posterior = np.log2(2/5)\n",
    "pos_bin_posterior = np.log2(2/5)\n",
    "neg_posterior = np.log2(3/5)\n",
    "neg_bin_posterior = np.log2(3/5)\n",
    "\n",
    "# Needed for word probabilities\n",
    "pos_count = sum(counters[\"pos\"].values())\n",
    "neg_count = sum(counters[\"neg\"].values())\n",
    "pos_bin_count = sum(counters_bin[\"pos\"].values())\n",
    "neg_bin_count = sum(counters_bin[\"neg\"].values())\n",
    "\n",
    "\n",
    "for word in sentance:\n",
    "    # Make sure word is known!\n",
    "    if word in counters[\"tot\"].keys():\n",
    "        pos_posterior += np.log2( (counters[\"pos\"][word] + 1) / (pos_count + len(counters[\"tot\"])))\n",
    "        neg_posterior += np.log2( (counters[\"neg\"][word] + 1) / (neg_count + len(counters[\"tot\"])))\n",
    "\n",
    "        pos_bin_posterior += np.log2( (counters_bin[\"pos\"][word] + 1) / (pos_bin_count + len(counters_bin[\"tot\"])))\n",
    "        neg_bin_posterior += np.log2( (counters_bin[\"neg\"][word] + 1) / (neg_bin_count + len(counters_bin[\"tot\"])))\n",
    "        \n",
    "print(\"Positive: \", pos_posterior, \" Negative: \", neg_posterior)\n",
    "print(\"=================\")\n",
    "print(\"Positive (bin): \", pos_bin_posterior, \" Negative: (bin)\", neg_bin_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives comments rightly classified:   0.7805907172995781\n",
      "negative comments rightly classified:   0.7534246575342466\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# HW - Predict the centiment of the product with NB classifier!\n",
    "# \n",
    "# Using product review dataset for sentiment analysis\n",
    "# http://people.mpi-inf.mpg.de/~smukherjee/data/\n",
    "# ====================\n",
    "\n",
    "def train_nb(all_documents, class_documents, C):\n",
    "    logprior = {}\n",
    "    likelihood = {}\n",
    "    # Make vocabulary of all documents!\n",
    "    vocabulary = set()\n",
    "    word_sum = 0\n",
    "    for review in all_documents:\n",
    "        for word in review:\n",
    "            vocabulary.add(word)\n",
    "            \n",
    "    # Loop all possible classes\n",
    "    for c in C:\n",
    "        N_docs = len(all_documents)\n",
    "        N_class_docs = len(class_documents[c])\n",
    "        logprior[c] = np.log2( N_class_docs/ N_docs )\n",
    "        \n",
    "        likelihood[c] = {}\n",
    "        # Calculate how many times a certain word appears with the class\n",
    "        counts = Counter([])\n",
    "        for review in class_documents[c]:\n",
    "            counts += Counter(ngrams(review, 1))\n",
    "            \n",
    "        word_sum = sum(counts.values())\n",
    "        # Loop all the words and calculate log-likelihoods\n",
    "        for word in vocabulary:\n",
    "            class_count = counts[(word,)]\n",
    "            likelihood[c][word] = np.log2((class_count + 1) / (word_sum + len(vocabulary)))\n",
    "        \n",
    "    return logprior, likelihood, vocabulary\n",
    "    \n",
    "def test_nb(document, logprior, likelihood, C, V):\n",
    "    total_sums = {}\n",
    "    # Loop all the classes and calculate sum for all the words\n",
    "    for c in C:\n",
    "        total_sums[c] = logprior[c]\n",
    "        for word in document:\n",
    "            if word in V:\n",
    "                total_sums[c] = total_sums[c] + likelihood[c][word]\n",
    "   \n",
    "    return total_sums\n",
    "    \n",
    "path = \"Dataset2.txt\"\n",
    "negative_reviews = []\n",
    "positive_reviews = []\n",
    "classes = [\"pos\", \"neg\"]\n",
    "\n",
    "with open(path) as f:\n",
    "    for line in f.readlines():\n",
    "        review = line.split('$')\n",
    "        tokenized = word_tokenize(review[2].lower())\n",
    "        \n",
    "        if review[1].strip() == \"neg\":\n",
    "            negative_reviews.append(tokenized)\n",
    "        else:\n",
    "            positive_reviews.append(tokenized)\n",
    "\n",
    "# Split the data!\n",
    "positive_train = positive_reviews[: int(len(positive_reviews) * 0.9)]\n",
    "negative_train = negative_reviews[: int(len(negative_reviews) * 0.9)]\n",
    "positive_test = positive_reviews[int(len(positive_reviews) * 0.9) + 1 :]\n",
    "negative_test = negative_reviews[int(len(negative_reviews) * 0.9) + 1 :]\n",
    "\n",
    "# I dont even know\n",
    "all_reviews = negative_train + positive_train\n",
    "review_dictionary = {}\n",
    "review_dictionary[\"neg\"] = negative_train\n",
    "review_dictionary[\"pos\"] = positive_train\n",
    "\n",
    "# Train the classifier!\n",
    "(log_priors, log_likelihoods, V) = train_nb(all_reviews, review_dictionary, classes)\n",
    "\n",
    "# Test the classifier!\n",
    "\n",
    "correct_positive = 0\n",
    "for test_item in positive_test:\n",
    "    likelihoods = test_nb(test_item,  log_priors, log_likelihoods, classes, V)\n",
    "    outcome = max(likelihoods.items(), key=operator.itemgetter(1))[0]\n",
    "    if outcome == \"pos\":\n",
    "        correct_positive += 1\n",
    "\n",
    "correct_negative = 0\n",
    "for test_item in negative_test:\n",
    "    likelihoods = test_nb(test_item,  log_priors, log_likelihoods, classes, V)\n",
    "    outcome = max(likelihoods.items(), key=operator.itemgetter(1))[0]\n",
    "    if outcome == \"neg\":\n",
    "        correct_negative += 1\n",
    "\n",
    "print(\"positives comments rightly classified:  \", correct_positive / len(positive_test))\n",
    "print(\"negative comments rightly classified:  \", correct_negative / len(negative_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
